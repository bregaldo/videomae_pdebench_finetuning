{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import torch\n",
    "sys.path.append(\"../src/\")\n",
    "from run_pdebench_finetuning import get_args, get_model, build_pdebench_dataset\n",
    "from engine_for_pdebench_finetuning import get_targets, unnorm_batch\n",
    "import utils\n",
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'pdebench_finetuning/k400_b/k400_b_turb_512_sweeps/dcc7rvql/k400_b_turb_512_sweeps_lr_0.008750'\n",
    "# model_dir = 'pdebench_finetuning/k400_s/k400_s_turb_512_4chan_test_2'\n",
    "\n",
    "args_json = os.path.join(utils.get_ceph_dir(), model_dir, \"args.json\")\n",
    "args = utils.load_args(args_json)\n",
    "\n",
    "args.num_workers = 1\n",
    "args.train_split_ratio = 0.8 # will have to be removed for new series of models\n",
    "args.test_split_ratio = 0.1 # will have to be removed for new series of models\n",
    "args.device = 'cuda:0'\n",
    "args.checkpoint = os.path.join(model_dir, 'checkpoint-49')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\t\t compNS_turb\n",
      "Fields:\t\t\t ['Vx', 'Vy', 'density', 'pressure']\n",
      "Model:\t\t\t pretrain_videomae_base_patch16_512_4chan\n",
      "Checkpoint:\t\t pdebench_finetuning/k400_b/k400_b_turb_512_sweeps/dcc7rvql/k400_b_turb_512_sweeps_lr_0.008750/checkpoint-49\n",
      "Batch size:\t\t 1\n",
      "Number of workers:\t 1\n",
      "Mask type:\t\t last_frame\n",
      "Mask ratio:\t\t 0.9\n",
      "Norm target mode:\t last_frame\n",
      "Num frames:\t\t 16\n",
      "Device:\t\t\t cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset:\\t\\t\", args.data_set)\n",
    "print(\"Fields:\\t\\t\\t\", args.fields)\n",
    "print(\"Model:\\t\\t\\t\", args.model)\n",
    "print(\"Checkpoint:\\t\\t\", args.checkpoint)\n",
    "print(\"Batch size:\\t\\t\", args.batch_size)\n",
    "print(\"Number of workers:\\t\", args.num_workers)\n",
    "print(\"Mask type:\\t\\t\", args.mask_type)\n",
    "print(\"Mask ratio:\\t\\t\", args.mask_ratio)\n",
    "print(\"Norm target mode:\\t\", args.norm_target_mode)\n",
    "print(\"Num frames:\\t\\t\", args.num_frames)\n",
    "print(\"Device:\\t\\t\\t\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: pretrain_videomae_base_patch16_512_4chan\n",
      "Position interpolate from 8x14x14 to 8x32x32\n",
      "Position interpolate from 8x14x14 to 8x32x32\n",
      "Adapting checkpoint for PDEBench\n",
      "Model loaded\n",
      "number of params: 94.80128 M\n",
      "Raw dataset compNS_turb has 1000 samples of shape (512, 512) and 21 timesteps.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(args.device)\n",
    "\n",
    "# Load model\n",
    "model = get_model(args)\n",
    "model.to(device)\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Model loaded\")\n",
    "print('number of params: {} M'.format(n_parameters / 1e6))\n",
    "\n",
    "# Load dataset\n",
    "dataset = build_pdebench_dataset(args, set_type='test')\n",
    "data_norm_tf = dataset.transform.transform.transforms[1] # CustomNormalize object to unnormalize data\n",
    "dataset.random_start = False\n",
    "\n",
    "# Data loader\n",
    "# sampler = torch.utils.data.RandomSampler(dataset)\n",
    "sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, sampler=sampler,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "        worker_init_fn=utils.seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_ouput(output):\n",
    "    p0, p1, p2 = 2, args.patch_size[0], args.patch_size[1]\n",
    "    c = len(args.fields)\n",
    "    t = 1 # For last frame prediction\n",
    "    h, w = args.window_size[-2:]\n",
    "    output = rearrange(output, 'b (t h w) (p0 p1 p2 c) -> b t c p0 (h p1) (w p2)', p0=p0, p1=p1, p2=p2, c=c, t=t, h=h, w=w)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_mse = nn.MSELoss()\n",
    "\n",
    "def loss_func_nmse(input, target, mean_dim=None):\n",
    "    x = torch.mean(torch.square(input - target), dim=(-1, -2)) / torch.mean(torch.square(target) + 1e-7, dim=(-1, -2))\n",
    "    return x.mean(dim=mean_dim)\n",
    "\n",
    "def loss_func_nrmse(input, target, mean_dim=None):\n",
    "    x = torch.sqrt(torch.mean(torch.square(input - target), dim=(-1, -2)) / torch.mean(torch.square(target) + 1e-7, dim=(-1, -2)))\n",
    "    return x.mean(dim=mean_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0853 +/- 0.0120\n",
      "NMSE: 0.1439 +/- 0.0178\n",
      "NRMSE: 0.3743 +/- 0.0229\n",
      "NRMSE Vx: 0.3943 +/- 0.0460\n",
      "NRMSE Vy: 0.3851 +/- 0.0406\n",
      "NRMSE density: 0.2912 +/- 0.0203\n",
      "NRMSE pressure: 0.4265 +/- 0.0312\n"
     ]
    }
   ],
   "source": [
    "## 1-step predictions\n",
    "\n",
    "losses_mse = []\n",
    "losses_nmse = []\n",
    "losses_nrmse = []\n",
    "losses_nrmse_per_field = []\n",
    "\n",
    "model.eval()\n",
    "for samples, masks in data_loader:\n",
    "    samples = samples.to(device, non_blocking=True)\n",
    "    samples_unnorm = data_norm_tf.unnormalize(samples.cpu())\n",
    "    \n",
    "    bool_masked_pos = masks.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "\n",
    "    p0, p1, p2 = 2, args.patch_size[0], args.patch_size[1]\n",
    "    nchan = samples.shape[1]\n",
    "    target = get_targets(samples, bool_masked_pos, args.norm_target_mode, p0=p0, p1=p1, p2=p2)\n",
    "    target_unnorm = samples_unnorm[:, :, -2:, :, :].squeeze()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(samples, bool_masked_pos)\n",
    "        outputs_unnorm = unnorm_batch(outputs,\n",
    "                                      norm_mode=args.norm_target_mode,\n",
    "                                      patch_size=(p0, p1, p2),\n",
    "                                      context=samples,\n",
    "                                      bool_masked_pos=bool_masked_pos)\n",
    "        outputs_unnorm = data_norm_tf.unnormalize(rearrange_ouput(outputs_unnorm.cpu())).squeeze()\n",
    "\n",
    "        # Only keep first frame\n",
    "        outputs_unnorm = outputs_unnorm[:, :1]\n",
    "        target_unnorm = target_unnorm[:, :1]\n",
    "\n",
    "        loss_mse = loss_func_mse(input=outputs_unnorm, target=target_unnorm)\n",
    "        loss_nmse = loss_func_nmse(input=outputs_unnorm, target=target_unnorm)\n",
    "        loss_nrmse = loss_func_nrmse(input=outputs_unnorm, target=target_unnorm)\n",
    "        loss_nrmse_per_field = loss_func_nrmse(input=outputs_unnorm, target=target_unnorm, mean_dim=1)\n",
    "        \n",
    "        loss_mse_value = loss_mse.item()\n",
    "        loss_nmse_value = loss_nmse.item()\n",
    "        loss_nrmse_value = loss_nrmse.item()\n",
    "        loss_nrmse_per_field_value = loss_nrmse_per_field.numpy()\n",
    "\n",
    "        losses_mse.append(loss_mse_value)\n",
    "        losses_nmse.append(loss_nmse_value)\n",
    "        losses_nrmse.append(loss_nrmse_value)\n",
    "        losses_nrmse_per_field.append(loss_nrmse_per_field_value)\n",
    "\n",
    "losses_mse = np.array(losses_mse)\n",
    "losses_nmse = np.array(losses_nmse)\n",
    "losses_nrmse = np.array(losses_nrmse)\n",
    "losses_nrmse_per_field = np.array(losses_nrmse_per_field)\n",
    "\n",
    "print(f\"MSE: {np.mean(losses_mse):.4f} +/- {np.std(losses_mse):.4f}\")\n",
    "print(f\"NMSE: {np.mean(losses_nmse):.4f} +/- {np.std(losses_nmse):.4f}\")\n",
    "print(f\"NRMSE: {np.mean(losses_nrmse):.4f} +/- {np.std(losses_nrmse):.4f}\")\n",
    "for i in range(len(args.fields)):\n",
    "    print(f\"NRMSE {args.fields[i]}: {np.mean(losses_nrmse_per_field[:, i]):.4f} +/- {np.std(losses_nrmse_per_field[:, i]):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('videomae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c78f739402b6efd8f9c4cbadeb4bb1722c2c6b5c02615425ba8de04008e590e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
